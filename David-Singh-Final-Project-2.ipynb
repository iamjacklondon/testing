{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accurately predicting claims severity (the dollar loss amount resulting from an insurance claim) is very important to an insurance company for several reasons:\n",
    "\n",
    "1. The longer a claim stays open, the more it will cost to eventually close. Closing claims earlier helps to reduce claim costs overall, and allows for efficient allocation of resources. \n",
    "2. Insurance companies are required to set aside funds that will eventually pay for claims. The amount of these funds should not be too high or too low. If they are too high, then that is money that could be better used elsewhere in the company. If the amount is too low, the company will eventually have to raise the amount to pay claims, and this movement may send the wrong signal to investors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allstate made data available for a Kaggle competition in 2016. Due to the sensitive nature of the data, both from the perspective of protecting the privacy of policyholders, and protecting the business interest of Allstate, much of the data is not easily translated to a data dictionary. Allstate has provided 116 categorical dimensions with no labeling. Many of these categories are likely easily guessed: for example, several of the categories have either an input of \"A\" or an input of \"B\". One of these categories is likely identifying \"male\" and \"female\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, Allstate provided 14 continuous variables. It appears that these variables have already been transformed, as the values for each input are all between 0 and 1. One of these likely represents age of the driver, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the algorithm is to use the provided to data to accurately predict claim severity, which is a continuous number. Due to the nature of the protected data, it is difficult to guess which variables may have greater or lesser value in predicting claim severity. That being said, I believe in general that claim severity can be predicted using detailed claim data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\Users\\dsingh\\Documents\\Data Science\\Allstate_Kaggle\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"loss\" amount in the final colum is what we are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA I WISH I HAD\n",
    "\n",
    "Other than the obvious (a data dictionary), there are a few items I would have liked to have tested. Examples:\n",
    "1. Date the accident occurred and date the claim was filed (I would have used the delta between these as a variable)\n",
    "2. A description of the claim from the initial filing of the claim (several sentences describing what happened, in the policyholder's words). I would have liked to have searched for key words that may have been signicant indicators of claim severity.\n",
    "\n",
    "The data I have is probably focused on details about the car(s) involved, the claimant(s) involved, and the type of loss (whether damage to a car, injury to a person, both, etc.). This is likely sufficient to come up with some good predictions.\n",
    "\n",
    "We also don't know what time period the data is from. I am assuming that there is no time series element involved - inflation certainly influences the cost of claims severity over time. But the time period is not explicitly stated, so it is another unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS I HAVE\n",
    "\n",
    "I am unclear on whether or not I can use multiple ML algorithms. I am assuming that I can, but I don't know what that might look like and what the protocols are. For example, can I use logistic regression or some other grouping algorithm to group my data into buckets, and then run linear regression on those buckets? Would that ever make sense to do? In general: how can I make this more nuanced than just using lasso and some gridsearch? \n",
    "\n",
    "Also: see below in \"Domain Knowledge\" section. Any thoughts on how I can apply domain knowledge given the limitations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTCOMES\n",
    "\n",
    "The output will be a set of claim severity predictions (a loss dollar amount prediciton for each row of data). It is difficult to know how accurate my model has to be in order to be considered a \"success\"; however, personal automobile insurance is an extremely competitive field. Any gain, even if not huge, is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target audience should be expecting the same output as I am expecting to produce: claim severity predictions. The target audience in this case is probably quite analytically sophisticated, given that Allstate already has a data science team in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said: it is difficult to know how successful the algorithm needs to be in order to achieve a gain, because we don't know how successful Allstate already is at anticipating claim severity with other methods already in place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOMAIN KNOWLEDGE\n",
    "\n",
    "I am an actuary working in the insurance industry, so I do have plenty of domain knowledge. I could have used this knowledge to create new variables (by combining some variables that we have), but not knowing what the variables are makes it a lot harder to apply domain knowledge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
